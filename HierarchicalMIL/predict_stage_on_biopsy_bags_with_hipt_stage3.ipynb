{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11333f2d",
   "metadata": {},
   "source": [
    "Breast cancer stage prediction from pathological whole slide images with hierarchical image pyramid transformers.\n",
    "Project developed under the \"High Risk Breast Cancer Prediction Contest Phase 2\" \n",
    "by Nightingale, Association for Health Learning & Inference (AHLI)\n",
    "and Providence St. Joseph Health\n",
    "\n",
    "Copyright (C) 2023 Zsolt Bedohazi, Andras Biricz, Istvan Csabai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb46db1e-b647-45bd-a04c-c01a3b3ec209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from model_hierarchical_mil_stage3_vit_level1 import HIPT_LGP_FC_STAGE3ONLY, Attn_Net_Gated\n",
    "from model_hierarchical_mil_stage3_resnet_level0 import HIPT_LGP_FC_STAGE3ONLY, Attn_Net_Gated\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import auc as calc_auc\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import ngsci"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f14017e8-372f-4c66-8dc5-8ba4c0fe72f6",
   "metadata": {},
   "source": [
    "## Load models from CV folds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcc132f4-b88d-47b5-afa4-8b8c753d500e",
   "metadata": {},
   "source": [
    "##### resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30629d8d-7982-45e7-b954-b8e50eb20283",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_dir_cv_0 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/runs_before_april26/checkpoints_cv5_balanced_run5/cv_0/'\n",
    "checkpoints_dir_cv_1 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/runs_before_april26/checkpoints_cv5_balanced_run5/cv_1/'\n",
    "checkpoints_dir_cv_2 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/runs_before_april26/checkpoints_cv5_balanced_run5/cv_2/'\n",
    "checkpoints_dir_cv_3 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/runs_before_april26/checkpoints_cv5_balanced_run5/cv_3/'\n",
    "checkpoints_dir_cv_4 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/runs_before_april26/checkpoints_cv5_balanced_run5/cv_4/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fcc2a4b-b97e-4284-a8da-1652160a1410",
   "metadata": {},
   "source": [
    "##### vit"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f61a928-adc0-4377-af54-14ae6994748f",
   "metadata": {},
   "source": [
    "checkpoints_dir_cv_0 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/two-nightingale-finetuned-vits_level1/checkpoints_cv5_balanced_run6/cv_0/'\n",
    "checkpoints_dir_cv_1 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/two-nightingale-finetuned-vits_level1/checkpoints_cv5_balanced_run6/cv_1/'\n",
    "checkpoints_dir_cv_2 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/two-nightingale-finetuned-vits_level1/checkpoints_cv5_balanced_run6/cv_2/'\n",
    "checkpoints_dir_cv_3 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/two-nightingale-finetuned-vits_level1/checkpoints_cv5_balanced_run6/cv_3/'\n",
    "checkpoints_dir_cv_4 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/two-nightingale-finetuned-vits_level1/checkpoints_cv5_balanced_run6/cv_4/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb63ea3e-dbb3-4afd-b862-406d2ce7bc3d",
   "metadata": {},
   "source": [
    "##### resnet10 fold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06648035-3790-497d-8fd7-0d22874c6fc9",
   "metadata": {},
   "source": [
    "scores:\n",
    "\n",
    "    0.8054431085623077\n",
    "    0.7990998543885838\n",
    "    0.7602979518607795\n",
    "    0.7814769456841988\n",
    "    0.7797447111810377\n",
    "    0.8201680607020354\n",
    "    0.7763702620577697\n",
    "    0.8226519769535041\n",
    "    0.7691339792819564\n",
    "    0.779663379238015"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7bc929b5-8219-4685-b240-c37d9ec91797",
   "metadata": {
    "tags": []
   },
   "source": [
    "checkpoints_dir_cv_0 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv10_balanced_with_test_set_run1/cv_0/'\n",
    "checkpoints_dir_cv_1 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv10_balanced_with_test_set_run1/cv_1/'\n",
    "checkpoints_dir_cv_2 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv10_balanced_with_test_set_run1/cv_2/'\n",
    "checkpoints_dir_cv_3 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv10_balanced_with_test_set_run1/cv_3/'\n",
    "checkpoints_dir_cv_4 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv10_balanced_with_test_set_run1/cv_4/'\n",
    "checkpoints_dir_cv_5 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv10_balanced_with_test_set_run1/cv_5/'\n",
    "checkpoints_dir_cv_6 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv10_balanced_with_test_set_run1/cv_6/'\n",
    "checkpoints_dir_cv_7 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv10_balanced_with_test_set_run1/cv_7/'\n",
    "checkpoints_dir_cv_8 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv10_balanced_with_test_set_run1/cv_8/'\n",
    "checkpoints_dir_cv_9 = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv10_balanced_with_test_set_run1/cv_9/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49c66b51-640f-47fc-ad8e-232fefb93aca",
   "metadata": {
    "tags": []
   },
   "source": [
    "checkpoints_dir_cv_0 = 'project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv5_balanced_run4/cv_0/'\n",
    "checkpoints_dir_cv_1 = 'project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv5_balanced_run4/cv_1/'\n",
    "checkpoints_dir_cv_2 = 'project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv5_balanced_run4/cv_2/'\n",
    "checkpoints_dir_cv_3 = 'project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv5_balanced_run4/cv_3/'\n",
    "checkpoints_dir_cv_4 = 'project/nightingale_breast_working_development_directory/Preprocessing/runs/nightingale-nofinetuned_resnet50_embeddings_level0/checkpoints_cv5_balanced_run4/cv_4/'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd1bd552-00e1-4cc9-b54a-35184464a6bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "checkpoints_dir_cv_0 = '/home/ngsci/project/nightingale_breast/Preprocessing/checkpoints_cv5_balanced_vit_level1_run9/cv_0/'\n",
    "checkpoints_dir_cv_1 = '/home/ngsci/project/nightingale_breast/Preprocessing/checkpoints_cv5_balanced_vit_level1_run9/cv_1/'\n",
    "checkpoints_dir_cv_2 = '/home/ngsci/project/nightingale_breast/Preprocessing/checkpoints_cv5_balanced_vit_level1_run9/cv_2/'\n",
    "checkpoints_dir_cv_3 = '/home/ngsci/project/nightingale_breast/Preprocessing/checkpoints_cv5_balanced_vit_level1_run9/cv_3/'\n",
    "checkpoints_dir_cv_4 = '/home/ngsci/project/nightingale_breast/Preprocessing/checkpoints_cv5_balanced_vit_level1_run9/cv_4/'\n",
    "\n",
    "#checkpoints_dir_cv_5 = '/home/ngsci/project/nightingale_breast/Preprocessing/checkpoints_cv5_balanced_run10_with_stage2_finetuned_on_nightingale_v2/cv_5/'\n",
    "#checkpoints_dir_cv_6 = '/home/ngsci/project/nightingale_breast/Preprocessing/checkpoints_cv5_balanced_run10_with_stage2_finetuned_on_nightingale_v2/cv_6/'\n",
    "#checkpoints_dir_cv_7 = '/home/ngsci/project/nightingale_breast/Preprocessing/checkpoints_cv5_balanced_run10_with_stage2_finetuned_on_nightingale_v2/cv_7/'\n",
    "#checkpoints_dir_cv_8 = '/home/ngsci/project/nightingale_breast/Preprocessing/checkpoints_cv5_balanced_run10_with_stage2_finetuned_on_nightingale_v2/cv_8/'\n",
    "#checkpoints_dir_cv_9 = '/home/ngsci/project/nightingale_breast/Preprocessing/checkpoints_cv5_balanced_run10_with_stage2_finetuned_on_nightingale_v2/cv_9/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac6753-9946-4a9b-86af-a1dcbe8dab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names_all_cv = np.array([ np.array( sorted(  glob.glob( os.path.join(eval(f\"checkpoints_dir_cv_{i}\"), \"*.pt\"))   )) for i in range(5) ], dtype=object)\n",
    "file_names_all_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052cd3bb-36c8-4b83-b1f2-73ca6172aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names_all_cv[0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cab60867-5ee7-416b-a131-9ce3aee4e510",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load biopsy bags -> input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d04e15-b048-4cd2-a6ec-19d1618b92e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "biopsy_bag_input_path = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/biopsy_embeddings/biopsy_bag_vit_xs_embeddings_nightingale-nofinetuned_resnet50_embeddings_level0/'\n",
    "biopsy_bag_input_path_holdout = '/home/ngsci/project/nightingale_breast_working_development_directory/Preprocessing/biopsy_embeddings/biopsy_bag_vit_xs_embeddings_nightingale-nofinetuned_resnet50_embeddings_level0_holdout/'\n",
    "\n",
    "biopsy_df_local_test = pd.read_csv('cv_splits_stratified_with_test_set_10fold/test_split_stratified.csv')\n",
    "biopsy_df_local_test.sort_values('biopsy_id', inplace=True)\n",
    "biopsy_bag_input_files_local_test = np.array( sorted([ biopsy_bag_input_path+i+'.npz' for i in biopsy_df_local_test.biopsy_id.values ]) )\n",
    "biopsy_bag_input_files_holdout = np.array(sorted([ biopsy_bag_input_path_holdout+k for k in os.listdir(biopsy_bag_input_path_holdout) if '.npz' in k ]))\n",
    "\n",
    "biopsy_bag_input_files_local_test.shape, biopsy_bag_input_files_holdout.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7badd80-64c4-4a25-966a-b7c0fa614766",
   "metadata": {},
   "source": [
    "## Look for best models based on AUC or VAL LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a744349-ac47-47b5-92c0-2d4b27ceb53f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_models_on_val_auc = []\n",
    "\n",
    "for i in range(file_names_all_cv.shape[0]):\n",
    "    # only first best models\n",
    "    #max_auc_index = np.argmax([float(os.path.basename(item).split('_')[3]) for item in file_names_all_cv[i]])\n",
    "    \n",
    "    # multiple best models\n",
    "    select = 10\n",
    "    max_auc_sort_index = np.argsort([float(os.path.basename(item).split('_')[3]) for item in file_names_all_cv[i]])[::-1]\n",
    "    \n",
    "    for m in range(select):\n",
    "        max_auc_model = file_names_all_cv[i][max_auc_sort_index[m]]\n",
    "        best_models_on_val_auc.append(max_auc_model)\n",
    "\n",
    "best_models_on_val_auc = np.array(best_models_on_val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e51d5-2a43-453f-a4ea-609c51e2c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_on_val_auc[::select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1b3d6-6bc7-41f9-9599-4e3ad11f1b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best 6\n",
    "best_models_on_val_loss = []\n",
    "\n",
    "for i in range(file_names_all_cv.shape[0]):\n",
    "    # only first best models\n",
    "    #max_auc_index = np.argmax([float(os.path.basename(item).split('_')[3]) for item in file_names_all_cv[i]])\n",
    "    \n",
    "    # multiple best models\n",
    "    select = 6\n",
    "    min_loss_sort_index = np.argsort([float(os.path.basename(item).split('_')[3]) for item in file_names_all_cv[i]])\n",
    "    \n",
    "    for m in range(select):\n",
    "        min_loss_model = file_names_all_cv[i][min_loss_sort_index[m]]\n",
    "        best_models_on_val_loss.append(min_loss_model)\n",
    "\n",
    "best_models_on_val_loss = np.array(best_models_on_val_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b984f0c3-21e4-49a3-a441-c88e5fff2282",
   "metadata": {},
   "source": [
    "##### best models on val loss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bac8804-8f7f-4308-a893-4322028e02c3",
   "metadata": {},
   "source": [
    "np.mean([float(e.split('_auc_')[0].split('_')[1]) for e in best_models_on_val_loss])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cf4486c-7cd3-4dff-b12b-80ea67dcb0da",
   "metadata": {},
   "source": [
    "##### best models on val auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658de2f6-99a9-45f1-811c-2f234019d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([float(e.split('_auc_')[1].split('_')[0]) for e in best_models_on_val_auc])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20638b68-1085-4c9a-83e3-7ed7a58062ff",
   "metadata": {},
   "source": [
    "## Predict with HIPT stage 3 ViT with model ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232e952-6aed-4df0-b6dd-39d432c126a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_true, y_pred):\n",
    "    if y_pred.shape != y_true.shape:\n",
    "        # try to one-hot encode y_true\n",
    "        y_true = F.one_hot(torch.from_numpy(y_true).to(torch.int64), 5)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    auc_all = []\n",
    "    for class_ind in range(y_pred.shape[-1]):\n",
    "        fpr, tpr, _ = roc_curve(y_true[:, class_ind], y_pred[:, class_ind])\n",
    "        auc = roc_auc_score(y_true[:, class_ind], y_pred[:, class_ind])\n",
    "        auc_all.append(auc)\n",
    "        plt.plot(fpr, tpr, '-', label='AUC : %.3f, label : %d' % (auc, class_ind))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return auc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8baed7-d121-40ae-82a3-71e5b97d7644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_with_one_model(model, biopsy_bag_input_files):\n",
    "    \n",
    "    preds_all = []\n",
    "    labels_all = []\n",
    "\n",
    "    for b in tqdm(range(biopsy_bag_input_files.shape[0])):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb_npy = np.load( biopsy_bag_input_files[b] )['embedding']\n",
    "\n",
    "            #if emb_npy.shape[0] > 15000:\n",
    "            #    rand_idx = np.random.permutation(emb_npy.shape[0])\n",
    "            #    emb_npy = emb_npy[rand_idx[:15000]]\n",
    "\n",
    "            emb = torch.from_numpy(np.expand_dims(emb_npy, 0).astype(np.float32)).to('cuda:0')\n",
    "            _, preds, label, _, _ = model(emb)\n",
    "\n",
    "\n",
    "        preds_all.append(preds.cpu().detach().numpy())\n",
    "        labels_all.append(label.cpu().numpy())\n",
    "        \n",
    "    preds_all = np.concatenate(preds_all)\n",
    "    labels_all = np.concatenate(labels_all)\n",
    "    \n",
    "    return preds_all, labels_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27cb3ec8-4d32-4339-a7f2-127e1aceefc4",
   "metadata": {},
   "source": [
    "### Local test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c8bace-ab39-4ee6-bd02-7e7b079e2d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#best_models_on_val_auc = best_models_on_val_loss # VAL LOSS\n",
    "\n",
    "nr_models = best_models_on_val_auc.shape[0]\n",
    "\n",
    "preds_ensemble_local_test = np.zeros((best_models_on_val_auc.shape[0], biopsy_bag_input_files_local_test.shape[0], 5))\n",
    "labels_ensmble_local_test = np.zeros((best_models_on_val_auc.shape[0], biopsy_bag_input_files_local_test.shape[0], 1))\n",
    "\n",
    "for m in range(nr_models):\n",
    "    \n",
    "    model = HIPT_LGP_FC_STAGE3ONLY() # define model\n",
    "    best_model_path = best_models_on_val_auc[m] # path of the m th best model\n",
    "    print(os.path.basename(best_model_path))\n",
    "    model_state_dict = torch.load(best_model_path, map_location=torch.device('cuda:0')) # load\n",
    "\n",
    "    model.load_state_dict(model_state_dict) # load weights\n",
    "    model.eval() # set to eval mode ! \n",
    "    model.to('cuda:0')\n",
    "    \n",
    "    preds_all, labels_all = pred_with_one_model(model, biopsy_bag_input_files_local_test)\n",
    "    \n",
    "    preds_ensemble_local_test[m] = preds_all\n",
    "    labels_ensmble_local_test[m] = labels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5840bd8-5b3b-4bc2-9ce2-2a7b3b259256",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ensemble_local_test.shape, labels_ensmble_local_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a91e36af-0baa-4553-bde4-cc19c029c060",
   "metadata": {},
   "source": [
    "np.save('preds_60ensemble_resnet_nofinetune_level0_cv10_test_run1_predictions_local_test.npy', preds_ensemble_local_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2e18ba9-3fda-4e0f-9d1b-17eb19c6caee",
   "metadata": {},
   "source": [
    "\n",
    "#### Simple mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f0e6f-a959-411c-a5a0-74aa4671f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_ensemble_local_test = np.mean(preds_ensemble_local_test, axis=0)\n",
    "final_label_ensemble_local_test = np.argmax(preds_ensemble_local_test, axis=-1)\n",
    "final_pred_ensemble_local_test.shape, final_label_ensemble_local_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46f6ac-a119-4656-84e5-c544e3475695",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = plot_roc( biopsy_df_local_test.stage.values, final_pred_ensemble_local_test  )\n",
    "#auc = plot_roc( biopsy_df_local_test.stage.values, preds_ensemble_local_test[3]  )\n",
    "print( np.mean(auc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38f825-bb30-4d8c-a8af-2a764c86f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_ensemble_local_test[:,4].max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3f8e898-ff91-4628-8380-cff55fd974d2",
   "metadata": {},
   "source": [
    "#### Filtering then mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870dd982-1a91-46bd-aa87-dcc12c7e028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_one_sample_colwise( current_sample ):\n",
    "    mean_sample = np.mean( current_sample, axis=0 )\n",
    "    std_sample = np.std( current_sample, axis=0 )\n",
    "\n",
    "    filted_sample = np.zeros(5)\n",
    "    for s in range(5):\n",
    "        filt_one_class = np.abs( current_sample[:,s] - mean_sample[s] ) < 1.5*std_sample[s]\n",
    "        filted_sample[s] = np.mean( current_sample[:, s][filt_one_class])\n",
    "    \n",
    "    # THIS CANNOT BE DONE -> so low probs for class 4 ! -> would filter those out\n",
    "    #noise_filt = filted_sample < 0.01\n",
    "    #filted_sample[noise_filt] = 0.0\n",
    "\n",
    "    filted_sample = filted_sample / np.sum(filted_sample)\n",
    "    \n",
    "    return filted_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5eaa8-1bee-421b-a40e-204fac3045ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ensemble_local_test_corr = np.array( [ filt_one_sample_colwise( preds_ensemble_local_test[:,q] ) for q in range(preds_ensemble_local_test.shape[1]) ] )\n",
    "final_pred_ensemble_local_test_corr = preds_ensemble_local_test_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f1b73a-fdc4-4297-bb6e-d4a338a24dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = plot_roc( biopsy_df_local_test.stage.values, final_pred_ensemble_local_test_corr  )\n",
    "print( np.mean(auc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b31d1e-7d0c-4c4e-ac1b-4d0dc65348c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_one_sample_all( current_sample ):\n",
    "    mean_sample = np.mean( current_sample, axis=0 )\n",
    "    dist_from_mean = np.sqrt( np.sum( (current_sample - mean_sample )**2, 1) )\n",
    "    #plt.hist(dist_from_mean) ## for testing\n",
    "    filt = dist_from_mean < np.percentile( dist_from_mean, 10 )\n",
    "    filted_sample = np.mean( current_sample[filt], axis=0 )\n",
    "\n",
    "    filted_sample = filted_sample / np.sum(filted_sample)\n",
    "    \n",
    "    return filted_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08940da1-f9fb-49e0-b382-133e9872c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ensemble_local_test_corr = np.array( [ filt_one_sample_all( preds_ensemble_local_test[:,q] ) for q in range(preds_ensemble_local_test.shape[1]) ] )\n",
    "final_pred_ensemble_local_test_corr = preds_ensemble_local_test_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434f052-fb08-4562-b60f-5f5691408842",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = plot_roc( biopsy_df_local_test.stage.values, final_pred_ensemble_local_test_corr  )\n",
    "print( np.mean(auc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4b2d3d-aa92-4753-bbaf-f70f40e1e193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filt_one_sample_all_upgraded( current_sample ):\n",
    "    mean_sample = np.mean( current_sample, axis=0 )\n",
    "    dist_from_mean = np.sqrt( np.sum( (current_sample - mean_sample )**2, 1) )\n",
    "    #plt.hist(dist_from_mean, bins=20) ## for testing\n",
    "    #filt = dist_from_mean < np.percentile( dist_from_mean, 20 )\n",
    "    #idx = np.argmin( np.diff( [ np.percentile( dist_from_mean, p ) for p in range(0,100,1)  ] ) )\n",
    "    filt = np.logical_and( dist_from_mean > np.percentile( dist_from_mean, 20 ), dist_from_mean < np.percentile( dist_from_mean, 80 ) )\n",
    "    #filt = np.logical_and( dist_from_mean > np.percentile( dist_from_mean, idx ), dist_from_mean < np.percentile( dist_from_mean, idx ) )\n",
    "    filted_sample = np.mean( current_sample[filt], axis=0 )\n",
    "\n",
    "    filted_sample = filted_sample / np.sum(filted_sample)\n",
    "    \n",
    "    return filted_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad9cc7-e0b8-498b-8a8c-a42ee37be48a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_ensemble_local_test_corr = np.array( [ filt_one_sample_all_upgraded( preds_ensemble_local_test[:,q] ) for q in range(preds_ensemble_local_test.shape[1]) ] )\n",
    "final_pred_ensemble_local_test_corr = preds_ensemble_local_test_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc863d02-920e-4084-9ca8-b8fec190f841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auc = plot_roc( biopsy_df_local_test.stage.values, final_pred_ensemble_local_test_corr  )\n",
    "print( np.mean(auc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa9f4f-09ce-4a5c-93d8-69ad6cef0e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bba6dbd1-0724-4e4e-bf9c-6b3f66d0cff9",
   "metadata": {},
   "source": [
    "### HOLDOUT set for leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462caf65-ca7d-4dbf-a4ea-9a904128788f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_models = best_models_on_val_auc.shape[0]\n",
    "\n",
    "preds_ensemble_holdout = np.zeros((best_models_on_val_auc.shape[0], biopsy_bag_input_files_holdout.shape[0], 5))\n",
    "labels_ensmble_holdout = np.zeros((best_models_on_val_auc.shape[0], biopsy_bag_input_files_holdout.shape[0], 1))\n",
    "\n",
    "for m in range(nr_models):\n",
    "    \n",
    "    model = HIPT_LGP_FC_STAGE3ONLY() # define model\n",
    "    best_model_path = best_models_on_val_auc[m] # path of the m th best model\n",
    "    model_state_dict = torch.load(best_model_path, map_location=torch.device('cuda:0')) # load\n",
    "\n",
    "    model.load_state_dict(model_state_dict) # load weights\n",
    "    model.eval() # set to eval mode ! \n",
    "    model.to('cuda:0')\n",
    "    \n",
    "    preds_all, labels_all = pred_with_one_model(model, biopsy_bag_input_files_holdout)\n",
    "    \n",
    "    preds_ensemble_holdout[m] = preds_all\n",
    "    labels_ensmble_holdout[m] = labels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14b0b43-736e-41ca-819f-948989ec9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ensemble_holdout.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f274ab6d-639c-47fa-b0b1-a8f1375ccb46",
   "metadata": {
    "tags": []
   },
   "source": [
    "nr_models = best_models_on_val_loss.shape[0]\n",
    "\n",
    "preds_ensemble = np.zeros((best_models_on_val_loss.shape[0], 886, 5))\n",
    "labels_ensmble= np.zeros((best_models_on_val_loss.shape[0], 886, 1))\n",
    "\n",
    "for m in range(nr_models):\n",
    "    \n",
    "    model = HIPT_LGP_FC_STAGE3ONLY()\n",
    "    \n",
    "    best_model_path = best_models_on_val_loss[m]\n",
    "    \n",
    "\n",
    "    model_state_dict = torch.load(best_model_path, map_location=torch.device('cuda:0'))\n",
    "\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    model.eval()\n",
    "    model.to('cuda:0')\n",
    "    \n",
    "    preds_all, labels_all = pred_with_one_model(model)\n",
    "    \n",
    "    preds_ensemble[m] = preds_all\n",
    "    labels_ensmble[m] = labels_all"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c847b45b-7f49-49fc-9f42-ae6e4a5d7543",
   "metadata": {},
   "source": [
    "np.save('preds_50ensemble_resnet_nofinetune_level0_cv5_run5_predictions.npy', preds_ensemble_holdout)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76b3ebcb-cade-4d9a-8fb6-00d0026d6727",
   "metadata": {},
   "source": [
    "np.save('preds_30ensemble_vit_two-finetune_level1_run6_predictions.npy', preds_ensemble)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd99c443-b0fe-46c0-8e65-571cc9ec505a",
   "metadata": {},
   "source": [
    "### Simple mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873534be-27a1-4b90-9836-9eb52ad11687",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_ensemble = np.mean(preds_ensemble_holdout, axis=0)\n",
    "final_label_ensemble = np.argmax(final_pred_ensemble, axis=-1)\n",
    "final_pred_ensemble.shape, final_label_ensemble.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264e8ae-8319-4cd2-9e35-389eadf01191",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_ensemble[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a64095c-7f92-4b50-8ae7-283fc951e0ae",
   "metadata": {},
   "source": [
    "### Corrigate with models around the mean of 100"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74dc2248-d782-4704-9c4a-3b0c756fe1ca",
   "metadata": {},
   "source": [
    "preds_ensemble_holdout_corr = np.array( [ filt_one_sample_all( preds_ensemble_holdout[:,q] ) for q in range(10,14) ] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80acfa7d-ff83-4049-ac50-2a4c5b1c8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ensemble_holdout_corr = np.array( [ filt_one_sample_all( preds_ensemble_holdout[:,q] ) for q in range(preds_ensemble_holdout.shape[1]) ] )\n",
    "final_pred_ensemble_holdout_corr = preds_ensemble_holdout_corr\n",
    "final_pred_ensemble_holdout_corr_labels = np.argmax(final_pred_ensemble_holdout_corr, axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff634448-fe90-4eae-a532-b62d938bacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_ensemble_holdout_corr[:10], final_pred_ensemble_holdout_corr_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5849cf-d1a6-419d-bf4a-cba0e737607e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_ensemble_holdout_corr = np.array( [ filt_one_sample_all_upgraded( preds_ensemble_holdout[:,q] ) for q in range(preds_ensemble_holdout.shape[1]) ] )\n",
    "final_pred_ensemble_holdout_corr = preds_ensemble_holdout_corr\n",
    "final_pred_ensemble_holdout_corr_labels = np.argmax(final_pred_ensemble_holdout_corr, axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e2385-7ec6-4845-8a4b-e59237aec2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_pred_ensemble_holdout_corr[:10], final_pred_ensemble_holdout_corr_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e668b61-b00f-4f5d-9f2d-6ef96f2c2ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_csv = pd.DataFrame(np.concatenate((np.array([os.path.basename(f).split('.npz')[0] for f in biopsy_bag_input_files_holdout]).reshape(-1,1), final_pred_ensemble_holdout_corr, final_pred_ensemble_holdout_corr_labels), axis=1), columns=None)\n",
    "pred_csv.columns = ['' for i in range(pred_csv.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf11184a-530e-4c6e-ab88-3946e5af6ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_csv.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bce8b576-26a6-4e56-a16e-c26160217fbe",
   "metadata": {},
   "source": [
    "pred_csv.to_csv('pred_csv_cv10_resnet_level0_with_test_mean_18th_submission_proposal.csv', index=None, header=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c347ac29-99fe-4c50-b692-67f8336c4747",
   "metadata": {},
   "source": [
    "pred_csv.to_csv('pred_csv_22th.csv', index=None, header=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "541a160a-3cc0-4fa7-a7ff-6e7bc3f37722",
   "metadata": {
    "tags": []
   },
   "source": [
    "ngsci.submit_contest_entry(\n",
    "    \"./pred_csv_22th.csv\", description=\"22th submission run5 resnet level0 nofinetuned cv5 huge ensemble filted\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c004d2-1947-40b8-b472-da180f769540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e719b0a0-7127-42dd-8a90-8f7b08ed4c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d53a4-8c21-44f4-8549-8dbe263f0d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e244f69d12f14f842eba482c16e5aadaedc716c5f259416fefc0a6e445229e62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
